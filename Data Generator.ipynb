{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import gc\n",
    "from sklearn.metrics import f1_score, accuracy_score, mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BT_filter(values):\n",
    "    BT_mean = []\n",
    "#     values = df.values\n",
    "    for idx in range(len(values)):\n",
    "        val_0 = idx-41\n",
    "        val_1 = idx-40\n",
    "        val_2 = idx-39\n",
    "        val_3 = idx-1\n",
    "        val_4 = idx\n",
    "        val_5 = idx+1\n",
    "        val_6 = idx+39\n",
    "        val_7 = idx+40\n",
    "        val_8 = idx+41\n",
    "        \n",
    "        val_4 = values[idx]\n",
    "        if val_0<0 or (val_0%40)==39:\n",
    "            val_0 = -1\n",
    "        else:\n",
    "            val_0 = values[val_0]\n",
    "            \n",
    "        if val_1<0:\n",
    "            val_1 = -1\n",
    "        else:\n",
    "            val_1 = values[val_1]\n",
    "            \n",
    "        if val_2<0 or (val_2%40) ==0:\n",
    "            val_2 = -1\n",
    "        else:\n",
    "            val_2 = values[val_2]\n",
    "            \n",
    "        if (val_3%40)==39:\n",
    "            val_3 = -1\n",
    "        else:\n",
    "            val_3 = values[val_3]\n",
    "            \n",
    "        if (val_5%40)==0:\n",
    "            val_5 = -1\n",
    "        else:\n",
    "            val_5 = values[val_5]\n",
    "            \n",
    "        if (val_6%40)==39 or val_6>=1600:\n",
    "            val_6 = -1\n",
    "        else:\n",
    "            val_6 = values[val_6]\n",
    "            \n",
    "        if val_7>=1600:\n",
    "            val_7 = -1\n",
    "        else:\n",
    "            val_7 = values[val_7]\n",
    "            \n",
    "        if (val_8%40)==0 or val_8>=1600:\n",
    "            val_8 = -1\n",
    "        else:\n",
    "            val_8 = values[val_8]\n",
    "\n",
    "        vals = np.array([val_0, val_1, val_2, val_3, val_4, val_5, val_6, val_7, val_8])\n",
    "        vals = np.array([k for k in vals if k>=0])\n",
    "        BT_mean.append(vals.mean())\n",
    "    return BT_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train_files = glob.glob('dataset/train/*.npy')          # train 파일들 로드\n",
    "test_files = glob.glob('dataset/test/*.npy')            # test 파일들 로드\n",
    "\n",
    "# train_files = sorted(train_files)                          # 파일명으로 정렬\n",
    "test_files = sorted(test_files)                          # 파일명으로 정렬\n",
    "\n",
    "# submission = pd.read_csv('dataset/sample_submission.csv')\n",
    "\n",
    "# train = pd.read_feather('dataset/train_missing_32.feather')              # missing_value가 있는 값들 없애고 32\n",
    "# test = pd.read_feather('dataset/test_missing_32.feather')              # missing_value가 있는 값들 없애고 32\n",
    "\n",
    "# train = train.iloc[int(train.shape[0]*0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# num=1\n",
    "# for idx in tqdm_notebook(range(len(train_files[7634*(num-1):7634*num]))):\n",
    "#     df = pd.DataFrame(np.load(train_files[idx]).reshape(1600,-1))\n",
    "#     df.columns = ['BT1', 'BT2', 'BT3' ,'BT4' ,'BT5', 'BT6', 'BT7', 'BT8', 'BT9', 'type', 'GMI_lon', 'GMI_lat', 'DPR_lon', 'DPR_lat', 'target']\n",
    "#     for bt in ['BT1', 'BT2', 'BT3' ,'BT4' ,'BT5', 'BT6', 'BT7', 'BT8', 'BT9']:\n",
    "#         df[bt+'_mean'] = BT_filter(df[bt].values)\n",
    "#     dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BT_mean_column = ['BT1','BT2','BT3','BT4','BT5','BT6','BT7','BT8','BT9']\n",
    "# for col1 in range(len(BT_mean_column)):\n",
    "#     for col2 in (range(col1, len(BT_mean_column), 1)):\n",
    "#         if col1!=col2:\n",
    "#             train[str(BT_mean_column[col1])+'-'+str(BT_mean_column[col2])] = train[BT_mean_column[col1]] - train[BT_mean_column[col2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BT_mean_column = ['BT1_mean','BT2_mean','BT3_mean','BT4_mean','BT5_mean','BT6_mean','BT7_mean','BT8_mean','BT9_mean']\n",
    "for col1 in range(len(BT_mean_column)):\n",
    "    for col2 in (range(col1, len(BT_mean_column), 1)):\n",
    "        if col1!=col2:\n",
    "            train[str(BT_mean_column[col1])+'-'+str(BT_mean_column[col2])+'_mean'] = train[BT_mean_column[col1]] - train[BT_mean_column[col2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BT_mean_column = ['BT1_mean','BT2_mean','BT3_mean','BT4_mean','BT5_mean','BT6_mean','BT7_mean','BT8_mean','BT9_mean']\n",
    "# for col1 in range(len(BT_mean_column)):\n",
    "#     for col2 in (range(col1, len(BT_mean_column), 1)):\n",
    "#         if col1!=col2:\n",
    "#             test[str(BT_mean_column[col1])+'-'+str(BT_mean_column[col2])] = test[BT_mean_column[col1]] - test[BT_mean_column[col2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# for idx in tqdm_notebook(range(len(test_files))):\n",
    "#     df = pd.DataFrame(np.load(test_files[idx]).reshape(1600,-1))\n",
    "#     df.columns = ['BT1', 'BT2', 'BT3' ,'BT4' ,'BT5', 'BT6', 'BT7', 'BT8', 'BT9', 'type', 'GMI_lon', 'GMI_lat', 'DPR_lon', 'DPR_lat']\n",
    "#     for bt in ['BT1', 'BT2', 'BT3' ,'BT4' ,'BT5', 'BT6', 'BT7', 'BT8', 'BT9']:\n",
    "#         df[bt+'_mean'] = BT_filter(df[bt].values)\n",
    "#     dfs.append(df)\n",
    "\n",
    "\n",
    "# dfs = []\n",
    "# for idx in tqdm_notebook(range(len(test_files))):\n",
    "#     df = pd.DataFrame(np.load(test_files[idx]).reshape(1600,-1))\n",
    "#     df.columns = ['BT1', 'BT2', 'BT3' ,'BT4' ,'BT5', 'BT6', 'BT7', 'BT8', 'BT9', 'type', 'GMI_lon', 'GMI_lat', 'DPR_lon', 'DPR_lat']\n",
    "#     dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "test = pd.concat(dfs)\n",
    "test = test.astype(np.float32).reset_index(drop=True)\n",
    "# test = test.drop(['BT1', 'BT2', 'BT3' ,'BT4' ,'BT5', 'BT6', 'BT7', 'BT8', 'BT9', 'type', 'GMI_lon', 'GMI_lat', 'DPR_lon', 'DPR_lat'],axis=1)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "test.to_feather('dataset/test_missing_btmean.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open('dataset/y_train_BT+mean_processing.pickle', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open('dataset/y_valid_BT+mean_processing.pickle', 'wb') as f:\n",
    "    pickle.dump(y_valid, f)\n",
    "X_train.reset_index(drop=True).to_feather('dataset/X_train_BT+mean_processing.feather')\n",
    "X_valid.reset_index(drop=True).to_feather('dataset/X_valid_BT+mean_processing.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# with open('dataset/y_train_BT+mean_processing.pickle', 'rb') as f:\n",
    "#     y_train = pickle.load(f)\n",
    "# with open('dataset/y_valid_BT+mean_processing.pickle', 'rb') as f:\n",
    "#     y_valid = pickle.load(f)\n",
    "# print('loaded')\n",
    "# X_train_1of2 = pd.read_feather('dataset/X_train_BT+mean_processing_1of2.feather')\n",
    "# print('loaded')\n",
    "# X_train_2of2 = pd.read_feather('dataset/X_train_BT+mean_processing_2of2.feather')\n",
    "# print('loaded')\n",
    "# X_valid_1of2 = pd.read_feather('dataset/X_valid_BT+mean_processing_1of2.feather')\n",
    "# print('loaded')\n",
    "# X_valid_2of2 = pd.read_feather('dataset/X_valid_BT+mean_processing_2of2.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
